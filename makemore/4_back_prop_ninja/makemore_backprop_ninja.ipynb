{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rToK0Tku8PPn"
   },
   "source": [
    "## makemore: becoming a backprop ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8sFElPqq8PPp"
   },
   "outputs": [],
   "source": [
    "# there no change change in the first several cells from last lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ChBbac4y8PPq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "klmu3ZG08PPr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abel', 'abelone', 'abigael', 'abigail', 'ada', 'adela', 'adelaide', 'adele']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open(\"nameses/girl_names.txt\", \"r\").read().splitlines()\n",
    "words = [word.lower() for word in words]\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BCQomLE_8PPs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 27: 'ä', 28: 'å', 29: 'æ', 30: 'ç', 31: 'é', 32: 'ø', 0: '.'}\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "V_zt2QHr8PPs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17019, 3]) torch.Size([17019])\n",
      "torch.Size([2145, 3]) torch.Size([2145])\n",
      "torch.Size([2065, 3]) torch.Size([2065])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):\n",
    "  X, Y = [], []\n",
    "\n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "eg20-vsg8PPt"
   },
   "outputs": [],
   "source": [
    "# ok biolerplate done, now we get to the action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MJPU8HT08PPu"
   },
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZlFLjQyT8PPu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4587\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QY-y96Y48PPv"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "8ofj1s6d8PPv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.0207, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "mO-8aqxK8PPw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually,\n",
    "# backpropagating through exactly all of the variables\n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "# -----------------\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "dprobs = 1 / probs * dlogprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdims=True)\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts_sum = -counts_sum**-2 * dcounts_sum_inv\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dnorm_logits = norm_logits.exp() * dcounts\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdims=True)\n",
    "                # dlog_temp = torch.zeros_like(logits)\n",
    "                # dlog_temp[logits.max(1).indices] = dlogit_maxes \n",
    "                # dlog_temp += dnorm_logits.clone()\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "dbngain = bnraw * dhpreact\n",
    "dbngain = dbngain.sum(0, keepdims=True)\n",
    "dbnbias = dhpreact.sum(0, keepdims=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdims=True)\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "dbndiff2 = 1./(n-1.) * dbnvar\n",
    "dbndiff += (2*bndiff) * dbndiff2\n",
    "dbnmeani = -1 * dbndiff.sum(0, keepdim=True)\n",
    "dhprebn = dbndiff.clone()\n",
    "dhprebn += (1./n * dbnmeani)\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "demb = dembcat.view(32,3,10)\n",
    "                # dC = torch.zeros_like(C) \n",
    "                # for i in range(Xb.shape[0]):\n",
    "                #     for j in range(Xb.shape[1]):\n",
    "                #         dC[Xb[i, j]] += demb[i, j]\n",
    "one_hot_Xb = F.one_hot(Xb, num_classes=33).float()  # Shape: (32, 3, 33)\n",
    "dC = torch.einsum('bji,bjk->ik', one_hot_Xb, demb)\n",
    "# -----------------\n",
    "\n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "ebLtYji_8PPw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.020659923553467 diff: -4.76837158203125e-07\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "-gCXbB4C8PPx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 6.51925802230835e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# -----------------\n",
    "# YOUR CODE HERE :)\n",
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits /= n\n",
    "# -----------------\n",
    "\n",
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(dlogits.detach(), cmap=\"CMRmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "hd-MkhB68PPy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(7.1526e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
    "# BatchNorm paper: https://arxiv.org/abs/1502.03167\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "POdeZSKT8PPy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "# -----------------\n",
    "# YOUR CODE HERE :)\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "# -----------------\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "wPy8DhqB8PPz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13563\n",
      "      0/ 200000: 4.0539\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "    # kick off optimization\n",
    "    for i in range(max_steps):\n",
    "        # minibatch construct\n",
    "        ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "        Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "        \n",
    "        # forward pass\n",
    "        emb = C[Xb] # embed the characters into vectors\n",
    "        embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "        # Linear layer\n",
    "        hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "        # BatchNorm layer\n",
    "        # -------------------------------------------------------------\n",
    "        bnmean = hprebn.mean(0, keepdim=True)\n",
    "        bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "        bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "        bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "        hpreact = bngain * bnraw + bnbias\n",
    "        # -------------------------------------------------------------\n",
    "        # Non-linearity\n",
    "        h = torch.tanh(hpreact) # hidden layer\n",
    "        logits = h @ W2 + b2 # output layer\n",
    "        loss = F.cross_entropy(logits, Yb) # loss function\n",
    "    \n",
    "        # backward pass\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "        # loss.backward() # use this for correctness comparisons, delete it later!\n",
    "        \n",
    "        # manual backprop! #swole_doge_meme\n",
    "        # -----------------\n",
    "        dlogprobs = torch.zeros_like(logprobs)\n",
    "        dlogprobs[range(n), Yb] = -1.0/n\n",
    "        dprobs = 1 / probs * dlogprobs\n",
    "        dcounts_sum_inv = (counts * dprobs).sum(1, keepdims=True)\n",
    "        dcounts = counts_sum_inv * dprobs\n",
    "        dcounts_sum = -counts_sum**-2 * dcounts_sum_inv\n",
    "        dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "        dnorm_logits = norm_logits.exp() * dcounts\n",
    "        dlogits = dnorm_logits.clone()\n",
    "        dlogit_maxes = (-dnorm_logits).sum(1, keepdims=True)\n",
    "        dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "        dh = dlogits @ W2.T\n",
    "        dW2 = h.T @ dlogits\n",
    "        db2 = dlogits.sum(0)\n",
    "        dhpreact = (1.0 - h**2) * dh\n",
    "        dbngain = bnraw * dhpreact\n",
    "        dbngain = dbngain.sum(0, keepdims=True)\n",
    "        dbnbias = dhpreact.sum(0, keepdims=True)\n",
    "        dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "        dembcat = dhprebn @ W1.T\n",
    "        dW1 = embcat.T @ dhprebn\n",
    "        db1 = dhprebn.sum(0)\n",
    "        demb = dembcat.view(32,3,10)\n",
    "        one_hot_Xb = F.one_hot(Xb, num_classes=33).float()  # Shape: (32, 3, 33)\n",
    "        dC = torch.einsum('bji,bjk->ik', one_hot_Xb, demb)\n",
    "\n",
    "        grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "        # -----------------\n",
    "        \n",
    "        # update\n",
    "        lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "        for p, grad in zip(parameters, grads):\n",
    "        # p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "            p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "        \n",
    "        # track stats\n",
    "        if i % 10000 == 0: # print every once in a while\n",
    "            print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "        lossi.append(loss.log10().item())\n",
    "\n",
    "        if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "          break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13563\n",
      "      0/ 200000: 4.0095\n",
      "  10000/ 200000: 1.9785\n",
      "  20000/ 200000: 2.4180\n",
      "  30000/ 200000: 1.3979\n",
      "  40000/ 200000: 1.8354\n",
      "  50000/ 200000: 1.9558\n",
      "  60000/ 200000: 1.8252\n",
      "  70000/ 200000: 1.3875\n",
      "  80000/ 200000: 1.4764\n",
      "  90000/ 200000: 1.8499\n",
      " 100000/ 200000: 1.7028\n",
      " 110000/ 200000: 1.8892\n",
      " 120000/ 200000: 1.5511\n",
      " 130000/ 200000: 1.7223\n",
      " 140000/ 200000: 1.5807\n",
      " 150000/ 200000: 1.6031\n",
      " 160000/ 200000: 1.9042\n",
      " 170000/ 200000: 2.2679\n",
      " 180000/ 200000: 1.5534\n",
      " 190000/ 200000: 1.4857\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "    # kick off optimization\n",
    "    for i in range(max_steps):\n",
    "    \n",
    "        # minibatch construct\n",
    "        ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "        Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "        \n",
    "        # forward pass\n",
    "        emb = C[Xb] # embed the characters into vectors\n",
    "        embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "        # Linear layer\n",
    "        hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "        # BatchNorm layer\n",
    "        # -------------------------------------------------------------\n",
    "        bnmean = hprebn.mean(0, keepdim=True)\n",
    "        bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "        bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "        bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "        hpreact = bngain * bnraw + bnbias\n",
    "        # -------------------------------------------------------------\n",
    "        # Non-linearity\n",
    "        h = torch.tanh(hpreact) # hidden layer\n",
    "        logits = h @ W2 + b2 # output layer\n",
    "        loss = F.cross_entropy(logits, Yb) # loss function\n",
    "        \n",
    "        # backward pass\n",
    "        for p in parameters:\n",
    "          p.grad = None\n",
    "        # loss.backward() # use this for correctness comparisons, delete it later!\n",
    "        \n",
    "        # manual backprop! #swole_doge_meme\n",
    "        # -----------------\n",
    "        dlogits = F.softmax(logits, 1)\n",
    "        dlogits[range(n), Yb] -= 1\n",
    "        dlogits /= n\n",
    "        # 2nd layer backprop\n",
    "        dh = dlogits @ W2.T\n",
    "        dW2 = h.T @ dlogits\n",
    "        db2 = dlogits.sum(0)\n",
    "        # tanh\n",
    "        dhpreact = (1.0 - h**2) * dh\n",
    "        # batchnorm backprop\n",
    "        dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "        dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "        dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "        # 1st layer\n",
    "        dembcat = dhprebn @ W1.T\n",
    "        dW1 = embcat.T @ dhprebn\n",
    "        db1 = dhprebn.sum(0)\n",
    "        # embedding\n",
    "        demb = dembcat.view(emb.shape)\n",
    "        dC = torch.einsum('bji,bjk->ik', one_hot_Xb, demb)\n",
    "        grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "        # -----------------\n",
    "        \n",
    "        # update\n",
    "        lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "        for p, grad in zip(parameters, grads):\n",
    "          # p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "          p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "        \n",
    "        # track stats\n",
    "        if i % 10000 == 0: # print every once in a while\n",
    "          print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "        lossi.append(loss.log10().item())\n",
    "        \n",
    "        \n",
    "        # if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "        #   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "ZEpI0hMW8PPz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 10)        | exact: False | approximate: True  | maxdiff: 9.313225746154785e-09\n",
      "(30, 200)       | exact: False | approximate: True  | maxdiff: 8.381903171539307e-09\n",
      "(200,)          | exact: False | approximate: True  | maxdiff: 8.847564458847046e-09\n",
      "(200, 33)       | exact: False | approximate: True  | maxdiff: 1.1175870895385742e-08\n",
      "(33,)           | exact: False | approximate: True  | maxdiff: 1.1175870895385742e-08\n",
      "(1, 200)        | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n",
      "(1, 200)        | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n"
     ]
    }
   ],
   "source": [
    "# useful for checking your gradients\n",
    "for p,g in zip(parameters, grads):\n",
    "  cmp(str(tuple(p.shape)), g, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "KImLWNoh8PP0"
   },
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training\n",
    "\n",
    "with torch.no_grad():\n",
    "  # pass the training set through\n",
    "  emb = C[Xtr]\n",
    "  embcat = emb.view(emb.shape[0], -1)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  # measure the mean/std over the entire training set\n",
    "  bnmean = hpreact.mean(0, keepdim=True)\n",
    "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "6aFnP_Zc8PP0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1.535506248474121\n",
      "val 1.9114959239959717\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "esWqmhyj8PP1"
   },
   "outputs": [],
   "source": [
    "# I achieved:\n",
    "# train 2.0718822479248047\n",
    "# val 2.1162495613098145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "xHeQNv3s8PP1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mona.\n",
      "gunn.\n",
      "hedelen.\n",
      "helma.\n",
      "teovedie.\n",
      "grlen.\n",
      "adeledit.\n",
      "ingelina.\n",
      "aleke.\n",
      "susanna.\n",
      "selle.\n",
      "marta.\n",
      "mi.\n",
      "sadbergini.\n",
      "jess.\n",
      "juli.\n",
      "jellenny.\n",
      "ulrid.\n",
      "magdel.\n",
      "halda.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "\n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # forward pass\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
    "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "      hpreact = embcat @ W1 + b1\n",
    "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "      logits = h @ W2 + b2 # (N, vocab_size)\n",
    "      # sample\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "\n",
    "    print(''.join(itos[i] for i in out))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
